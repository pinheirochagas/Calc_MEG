{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to decode operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline \n",
    "\n",
    "import mne\n",
    "from mne.datasets import spm_face\n",
    "from mne.decoding import GeneralizationAcrossTime\n",
    "import sys\n",
    "import os.path as op\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "#Add personal functions to python path\n",
    "sys.path.append('/neurospin/meg/meg_tmp/Calculation_Pedro_2014/scripts/decoding/')\n",
    "#sys.path.append('/Volumes/NeuroSpin2T/Calculation_Pedro_2014/scripts/decoding/')\n",
    "from fldtrp2mne_calc import fldtrp2mne_calc\n",
    "from calc_ClassifyTwoCond import calc_ClassifyTwoCond\n",
    "from sklearn import svm\n",
    "from sklearn.cross_validation import cross_val_score, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.cross_validation import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Directories\n",
    "data_path = '/neurospin/meg/meg_tmp/Calculation_Pedro_2014/data/mat/'\n",
    "result_path = '/neurospin/meg/meg_tmp/Calculation_Pedro_2014/data/decoding/'\n",
    "#data_path = '/Volumes/NeuroSpin2T/Calculation_Pedro_2014/data/mat/'\n",
    "#result_path = '/Volumes/NeuroSpin2T/Calculation_Pedro_2014/data/decoding/'\n",
    "\n",
    "#Subjects\n",
    "#subjects = ['s01', 's02', 's03', 's04', 's05', 's06', 's07', 's08', 's09', 's10', \n",
    "            #'s11', 's12', 's13', 's14', 's15', 's16', 's17', 's18','s19', 's21', 's22']\n",
    "\n",
    "subjects = ['s07']\n",
    "\n",
    "\n",
    "#General parameters\n",
    "baseline = (-0.5, -0.05)\n",
    "\n",
    "downsmpDec = 100\n",
    "\n",
    "#Decoding\n",
    "trainset = 'attention'\n",
    "testset = 'calculation'\n",
    "decCond = ['left-right_add-sub']\n",
    "\n",
    "params = {'baseline': baseline, 'downsmpDec': downsmpDec, 'Classification': decCond, \n",
    "          'trainset': trainset, 'testset': testset}\n",
    "\n",
    "#Results initialization\n",
    "all_scores = []\n",
    "all_diagonals = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline-correcting data for subject: s07\n",
      "Applying baseline correction ... (mode: mean)\n",
      "Applying baseline correction ... (mode: mean)\n",
      "Decoding subject: s07\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot convert dictionary update sequence element #0 to a sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-b83608d6f51a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Decoding subject: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msub\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m     \u001b[0mgat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiagonal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalc_ClassifyTwoCond\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m     \u001b[0mgat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;31m#gat.plot_diagonal()  # plot decoding across time (correspond to GAT diagonal)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/neurospin/meg/meg_tmp/Calculation_Pedro_2014/scripts/decoding/calc_ClassifyTwoCond.pyc\u001b[0m in \u001b[0;36mcalc_ClassifyTwoCond\u001b[1;34m(X_train, y_train, X_test, y_test, params)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;31m###Learning process###\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m     \u001b[0mgat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGeneralizationAcrossTime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_times\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'trainingTime'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_times\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'testingTime'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict_mode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'mean-prediction'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m     \u001b[0mgat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/volatile/anaconda/lib/python2.7/site-packages/mne/decoding/time_gen.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, picks, cv, clf, train_times, test_times, predict_mode, scorer, n_jobs)\u001b[0m\n\u001b[0;32m    866\u001b[0m             \u001b[0mpicks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpicks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_times\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    867\u001b[0m             \u001b[0mtest_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_times\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpredict_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscorer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 868\u001b[1;33m             n_jobs=n_jobs)\n\u001b[0m\u001b[0;32m    869\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/volatile/anaconda/lib/python2.7/site-packages/mne/decoding/time_gen.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, picks, cv, clf, train_times, test_times, predict_mode, scorer, n_jobs)\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[1;31m# Define training sliding window\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         self.train_times = (_DecodingTime() if train_times is None\n\u001b[1;32m---> 78\u001b[1;33m                             else _DecodingTime(train_times))\n\u001b[0m\u001b[0;32m     79\u001b[0m         \u001b[1;31m# Define testing sliding window. If None, will be set in predict()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtest_times\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot convert dictionary update sequence element #0 to a sequence"
     ]
    }
   ],
   "source": [
    "for sub in subjects:\n",
    "    #Load data\n",
    "    fname_train = op.join(data_path, sub + '_vsa.mat') \n",
    "    fname_test = op.join(data_path, sub + '_calc.mat') \n",
    "\n",
    "    epoch_train,info_train = fldtrp2mne_calc(fname_train, 'data', 'vsa')\n",
    "    epoch_test,info_test = fldtrp2mne_calc(fname_test, 'data', 'calc')\n",
    "\n",
    "    #Baseline-correct & filter data\n",
    "    print('Baseline-correcting data for subject: ' + sub)\n",
    "    epoch_train.apply_baseline(baseline)\n",
    "    epoch_test.apply_baseline(baseline)\n",
    "\n",
    "    #Define sets index and trialinfo  \n",
    "    idx_trainSet = info_train['congruency'] == 1\n",
    "    idx_testSet = info_test['operator'] != 0  \n",
    "    info_train = info_train[idx_trainSet]\n",
    "    # Correct the cue labels\n",
    "    info_train[info_train['cue'] == 1] = -1\n",
    "    info_train[info_train['cue'] == 2] = 1\n",
    "    info_test = info_test[idx_testSet]\n",
    "    labels_train = 'cue'\n",
    "    labels_test = 'operator'\n",
    "    \n",
    "    #idx_testSet = idx_trainSet\n",
    "    #info_test = info_train\n",
    "    #labels_test = labels_train\n",
    "    \n",
    "    # Decoding train\n",
    "    X_train = epoch_train[idx_trainSet] #\n",
    "    y_train = np.array(info_train[labels_train]) #\n",
    "    y_train = y_train.astype(numpy.float64)\n",
    "    # Downsampling for decoding\n",
    "    X_train.decimate(downsmpDec)\n",
    "    #params.update({'testingTime':np.array(X_train.times)}) #Define test time\n",
    "    # Correct the above line by something like this:\n",
    "    # trainTime = {'start': 0, 'stop': 0.833, 'step': 0.833, 'length': 0.833}\n",
    "\n",
    "    \n",
    "    # Decoding test\n",
    "    X_test = epoch_test[idx_testSet]#\n",
    "    y_test = np.array(info_test[labels_test]) #\n",
    "    y_test = y_test.astype(numpy.float64)\n",
    "    # Downsampling for decoding\n",
    "    X_test.decimate(downsmpDec)\n",
    "    #params.update({'testingTime':np.array(X_test.times)}) #Define test time\n",
    "\n",
    "    \n",
    "    print('Decoding subject: ' + sub)\n",
    "    gat, score, diagonal = calc_ClassifyTwoCond(X_train, y_train, X_test, y_test, params)\n",
    "    gat.plot()\n",
    "    #gat.plot_diagonal()  # plot decoding across time (correspond to GAT diagonal)\n",
    "\n",
    "    #Store scores of different subjects in the same list\n",
    "    all_scores.append(score)\n",
    "    all_diagonals.append(diagonal)\n",
    "    \n",
    "#Transform into a numpy array   \n",
    "all_scores = np.array(all_scores)\n",
    "all_diagonals = np.array(all_diagonals)\n",
    "\n",
    "# Save individual results\n",
    "fname = op.join(result_path, 'Classification_ ' + '_Trainset_' + trainset + '_Testset_' + testset) \n",
    "np.save(fname, all_scores)\n",
    "\n",
    "# Compute group averages\n",
    "group_scores = np.mean(all_scores, 0)\n",
    "sem_group_scores = stats.sem(all_scores, 0)\n",
    "\n",
    "group_diagonal = np.mean(all_diagonals, 0)\n",
    "sem_group_diagonal = stats.sem(all_diagonals, 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Classification': ['left-right_add-sub'],\n",
       " 'baseline': (-0.5, -0.05),\n",
       " 'downsmpDec': 100,\n",
       " 'testingTime': array([-0.5, -0.1,  0.3,  0.7,  1.1,  1.5,  1.9,  2.3,  2.7,  3.1,  3.5,\n",
       "         3.9,  4.3]),\n",
       " 'testset': 'calculation',\n",
       " 'trainingTime': array([-0.5, -0.1,  0.3,  0.7,  1.1,  1.5,  1.9]),\n",
       " 'trainset': 'attention'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-10-799bac463771>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-10-799bac463771>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    params{testingTime}\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "params{testingTime}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plotting  \n",
    "\n",
    "# Plot GAT\n",
    "plt.imshow(group_scores, origin = 'lower', extent = [X_train.times[0], X_train.times[len(X_train.times)-1], \n",
    "                                                     X_train.times[0], X_train.times[len(X_train.times)-1]]) #flip the matrix around\n",
    "plt.axvline(0, color = 'k') #mark stimulus onset\n",
    "plt.axhline(0, color = 'k') #mark stimulus onset\n",
    "plt.colorbar()\n",
    "plt.xlabel('Testing Time (s)')\n",
    "plt.ylabel('Training Time (s)')\n",
    "plt.title('Group average generalization across time \\n Classification: ' + decCond[0] + ' vs ' \n",
    "+ decCond[1] + '\\n Trainset: ' + trainset + ', Testset: ' + testset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot Diagonal\n",
    "plt.plot(X_train.times, group_diagonal, label = \"Classification score\")\n",
    "plt.axvline(0, color = 'k') #mark stimulus onset\n",
    "plt.axvline(.8, color = 'k') #mark stimulus onset\n",
    "plt.axvline(1.6, color = 'k') #mark stimulus onset\n",
    "plt.axvline(2.4, color = 'k') #mark stimulus onset\n",
    "plt.axvline(3.2, color = 'k') #mark stimulus onset\n",
    "plt.axvline(3.6, color = 'k') #mark stimulus onset\n",
    "\n",
    "plt.axhline(0.25, color = 'k', ls = '--', label = \"Chance\") #mark chance level\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Classification Score (%)')\n",
    "plt.title('Cl assification: ' + decCond[0] + ' vs ' \n",
    "+ decCond[1] + '\\n Trainset: ' + trainset + ', Testset: ' + testset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "group_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = 'a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a == 'a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
